{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import t_sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def getWords(text, stopwords):\n",
    "    splitted_text = text.split()\n",
    "    new_splitted_text = []\n",
    "    for item in splitted_text:\n",
    "        if len(item) == 1:\n",
    "            item = item.lower()\n",
    "        new_splitted_text.append(item)\n",
    "    new_text = \" \".join(new_splitted_text)\n",
    "    new_text = re.sub(\"\\.\", \" \", new_text)\n",
    "    new_text = re.sub(\"_\", \"\", new_text)\n",
    "    new_text = re.sub(\"(?<= [A-Z]{1}) +((?=[A-Z] )|(?=[A-Z]$))\", \"\", new_text)\n",
    "    all_words = re.compile('\\w+').findall(new_text)\n",
    "    return [words.lower() for words in all_words if len(words)>1 and words.lower() not in stopwords]\n",
    "\n",
    "def getBigrams(text, stopwords):\n",
    "    splitted_text = text.split()\n",
    "    new_splitted_text = []\n",
    "    for item in splitted_text:\n",
    "        if len(item) == 1:\n",
    "            item = item.lower()\n",
    "        new_splitted_text.append(item)\n",
    "    new_text = \" \".join(new_splitted_text)\n",
    "    new_text = re.sub(\"\\.\", \" \", new_text)\n",
    "    new_text = re.sub(\"_\", \"\", new_text)\n",
    "    new_text = re.sub(\"(?<= [A-Z]{1}) +((?=[A-Z] )|(?=[A-Z]$))\", \"\", new_text)\n",
    "    all_words = re.compile('\\w+').findall(new_text)\n",
    "    lower_words = [words.lower() for words in all_words if len(words)>1 and words.lower() not in stopwords]\n",
    "    return [\" \".join(sorted(lower_words[i:i+2])) for i in range(len(lower_words)-1)]\n",
    "\n",
    "def getTerms(test, stopwords):\n",
    "    return getWords(test, stopwords) + getBigrams(test, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv(\"stopwords.csv\").as_matrix()\n",
    "stopwords.resize(stopwords.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"titles_books.csv\")\n",
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "train_titles = [getWords(title, stopwords) for title in train_data.title]\n",
    "test_titles = [title for title in test_data.title]\n",
    "\n",
    "i = 0\n",
    "labels = [0]\n",
    "for j in range(test_data.shape[0])[1:]:\n",
    "    if test_data.book_title[j-1]!=test_data.book_title[j]:\n",
    "        i += 1\n",
    "    labels.append(i)\n",
    "test_data['label'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VECTOR_DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 48454 words, keeping 9014 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 95485 words, keeping 11817 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 140148 words, keeping 14264 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 186623 words, keeping 16607 word types\n",
      "INFO:gensim.models.word2vec:collected 17484 word types from a corpus of 207117 raw words and 44357 sentences\n",
      "INFO:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:gensim.models.word2vec:min_count=0 retains 17484 unique words (100% of original 17484, drops 0)\n",
      "INFO:gensim.models.word2vec:min_count=0 leaves 207117 word corpus (100% of original 207117, drops 0)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 17484 items\n",
      "INFO:gensim.models.word2vec:sample=0.001 downsamples 23 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 202663 word corpus (97.8% of prior 207117)\n",
      "INFO:gensim.models.word2vec:estimated required memory for 17484 words and 32 dimensions: 13217904 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.models.word2vec:training model with 3 workers on 17484 vocabulary and 32 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO:gensim.models.word2vec:expecting 44357 sentences, matching count from corpus used for vocabulary survey\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 62.67% examples, 634909 words/s, in_qsize 6, out_qsize 0\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:training on 1035585 raw words (1013298 effective words) took 1.6s, 634698 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(train_titles, size=VECTOR_DIM, min_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pierścienia', 0.9816210865974426),\n",
       " ('hobbit', 0.9810181856155396),\n",
       " ('kropce', 0.9804226756095886),\n",
       " ('pierscieni', 0.9801980257034302),\n",
       " ('skibniewska', 0.9798970222473145),\n",
       " ('jrr', 0.9785947799682617),\n",
       " ('tolkien', 0.9776356220245361),\n",
       " ('kropka', 0.9765268564224243),\n",
       " ('powrotem', 0.9752150177955627),\n",
       " ('yeskov', 0.9746350049972534),\n",
       " ('silmarillion', 0.9732321500778198),\n",
       " ('pierścieni', 0.9731463193893433),\n",
       " ('nuda', 0.971091628074646),\n",
       " ('dwie', 0.9690154194831848),\n",
       " ('mórz', 0.968645453453064),\n",
       " ('dżil', 0.9684089422225952),\n",
       " ('podlesia', 0.9673435688018799),\n",
       " ('rudy', 0.9656370878219604),\n",
       " ('tam', 0.964540421962738),\n",
       " ('czyli', 0.9625658392906189)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_word(word=\"władca\".lower(), topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_score(model, word):\n",
    "    try:\n",
    "        score = model.wv[word]\n",
    "    except:\n",
    "        score = np.repeat(np.nan, repeats=VECTOR_DIM)\n",
    "    return score\n",
    "\n",
    "def get_title_score(model, title, stopwords):\n",
    "    title_parsed = getWords(title, stopwords)\n",
    "    mean_score = np.nanmean([get_word_score(model, i) for i in title_parsed], axis = 0) #nanmean to jak na.rm=TRUE w R\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.6343"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = get_title_score(model, \"Tolkien - Władca pierścieni - Trylogia\", stopwords)\n",
    "v2 = get_title_score(model, \"NAUKA ŚWIATA DYSKU I - Terry Pratchett\", stopwords)\n",
    "np.sum((v1-v2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vectorized_titles = np.array([get_title_score(model, title, stopwords) for title in train_data.title])\n",
    "vectorized_test_titles = np.array([get_title_score(model, title, stopwords) for title in test_data.title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vectorized_titles_sample = vectorized_titles[np.random.choice(vectorized_titles.shape[0], size = 20000, replace = False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### T-SNE visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsne_transformer = MulticoreTSNE(verbose = 1, n_jobs=4, perplexity=20, n_iter=2000, angle=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tnsed_titles = tsne_transformer.fit_transform(vectorized_test_titles.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bokeh.core.state:Session output file 'bokeh_vis/test_data_bokeh_vis.html' already exists, will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource\n",
    "from bokeh.models import HoverTool, CategoricalColorMapper\n",
    "from bokeh.palettes import inferno, Category20, Category20c, Category20b, Category10\n",
    "\n",
    "output_file(\"bokeh_vis/test_data_bokeh_vis.html\")\n",
    "\n",
    "source = ColumnDataSource(\n",
    "        data=dict(\n",
    "            x=tnsed_titles[:, 0],\n",
    "            y=tnsed_titles[:, 1],\n",
    "            desc=test_titles,\n",
    "            label = [i for i in test_data.label]\n",
    "        )\n",
    "    )\n",
    "color_mapper = CategoricalColorMapper(factors=[i for i in test_data.label.unique()], palette=Category10[10]*5)\n",
    "\n",
    "hover = HoverTool(\n",
    "        tooltips=[\n",
    "            (\"index\", \"$index\"),\n",
    "            (\"(x,y)\", \"($x, $y)\"),\n",
    "            (\"desc\", \"@desc\"),\n",
    "            (\"label\", \"@label\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "p = figure(plot_width=600, plot_height=600, tools=[hover],\n",
    "           title=\"Mouse over the dots\")\n",
    "\n",
    "p.circle('x', 'y', size=2, source=source, color={'field': 'label', 'transform': color_mapper})\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.io import show\n",
    "from bokeh.models import ColumnDataSource, CategoricalColorMapper\n",
    "from bokeh.palettes import RdBu3\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "source = ColumnDataSource(dict(\n",
    "    x=[1, 2, 3, 4, 5, 6],\n",
    "    y=[2, 1, 2, 1, 2, 1],\n",
    "    label=['hi', 'lo', 'hi', 'lo', 'hi', 'lo']\n",
    "))\n",
    "color_mapper = CategoricalColorMapper(factors=['hi', 'lo'], palette=[RdBu3[2], RdBu3[0]])\n",
    "\n",
    "p = figure(x_range=(0, 7), y_range=(0, 3), height=300, tools='save')\n",
    "p.circle(\n",
    "    x='x', y='y', radius=0.5, source=source,\n",
    "    fill_color={'field': 'label', 'transform': color_mapper},\n",
    "    legend='label'\n",
    ")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
